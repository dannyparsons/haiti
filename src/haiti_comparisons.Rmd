---
title: "Haiti Comparisons"
author: "Danny Parsons"
date: "11/06/2020"
output: 
  html_document:
    fig_width: 12
    fig_height: 6
---

```{r packages, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
library(here)
library(ggplot2)
library(lubridate)
library(reshape2)
library(viridis)
library(RColorBrewer)
library(tidyr)
library(hydroGOF)
library(stringr)
library(knitr)
library(kableExtra)
library(rnaturalearthdata)
library(rnaturalearth)
library(ggrepel)
library(sp)
library(tibble)
library(verification)
library(purrr)
library(dplyr)
library (ggspatial)
library(sf)
```

```{r setup, include=FALSE}
source(here("helper_funs.R"))
zm <- readRDS(here("daily_data_sorted1.RDS"))

zm <- zm$get_data_frame("merge")
zm <- filter(zm, station != "thiotte")
view(zm)

zm <- transmute (zm , 
              station = station,
              latitde = latitude,
              longitude = longitude, 
              year = year(date),
              month = month(date),
              day = day(date),
              rain = rain,
              date = date, 
              chirps_rain = chirps_rain
              
              )

view(zm)
quality_control<- filter(zm, month == c(6:11) ,rain == 0, chirps_rain >0)

quality_control$rain <-NA

view (quality_control)
if(anyDuplicated(zm %>%dplyr::select(station,date))) stop("Duplicates found!")
# 1 Jan = 1
s_doy_start <- 1
zm$date <- as.Date(zm$date)
zm <- zm %>% mutate(doy = yday_366(date),
                    s_doy = (doy - s_doy_start + 1) %% 366,
                    s_doy = ifelse(s_doy == 0, 366, s_doy),
                    year = year(date),
                    syear = ifelse(s_doy > (366 - s_doy_start + 1), year - 1, year),
                    month = month(date),
                    month = factor(month, levels = c(1:12)), #change
                    month_abb = factor(month, labels = month.abb[c(1:12)]),
                    rain = rain

)
zm_long_st <- zm %>% 
  melt(id.vars = c("station", "date", "year", "syear", "month", "month_abb", 
                   "doy", "s_doy"),
       measure.vars = names(zm)[endsWith(names(zm), "rain")][-1],
       variable.name = "product", value.name = "pr_rain")

# view (zm_long_st)
#the melt function takes data in a wide range of formats and stacks a set of columns into a single column of data

#creates a rainday column where the values are true or false depending on if there is rain that day or not
zm_long <- zm %>% 
  melt(id.vars = c("station", "date", "year", "syear", "month", "month_abb", "doy", "s_doy"),
       measure.vars = names(zm)[endsWith(names(zm), "rain")],
       variable.name = "product", value.name = "rain") %>%
  mutate(rainday = rain > 1)
# view(zm_long)


zm_long$product <- recode(zm_long$product, rain = "station")
stations <- c( "cap_hatien","quanaminthe", "jeremie", "damien", "petitionville", "jacmel", "les_cayes") #north to south would be a better order for these 
products <- levels(zm_long$product)
products <- products[-1]
names(products) <- substr(products, 1, nchar(products) - 5)
# view(zm_long)

metadata_station <- read.csv(here("daily_metadata.csv"))


# view(metadata_station)



metadata_station$station <- factor(metadata_station$station, levels = stations) #making the station column a factor and setting the levels 
# view (metadata_station)
zm_long$station <- factor(zm_long$station, levels = stations)
# view(zm_long)
by_station <- zm_long %>%
  group_by(station) %>%
  filter(!is.na(rain)) %>%
  summarise(first_date = first(date), #this line of code seems to be giving the same last date for all our data 
            last_date = last(date))

# view(by_station)


metadata_station <- left_join(metadata_station, by_station, by = "station")

# view(metadata_station) #get rid of column x 
rm(by_station)



skable <- function(kable_input) {
  kable_input %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed"),
                                full_width = FALSE)
}
```

## Stations

- Mansa is the only station in the North. 
- It's results are different to the other three, which could be the location or the quality of the station
- Would be useful to have further stations in the North
- Station data filtered to start in 1979 (earliest product year)

```{r}
metadata_station %>% 
  dplyr::select(station, latitude, longitude) %>%   ##may have to add a min year/max year column
  kable(digits = 2) %>%
  skable()
```


```{r station_map, fig.width=9, fig.height=4.5}
hti_admbnda_adm0_cnigs_20181129 <- sf::st_read(quiet=TRUE, dsn="C:/Users/User/OneDrive - Nexus365/Documents/Downloads/hti_adm_cnigs_20181129/hti_admbnda_adm0_cnigs_20181129.shp") %>% 
  dplyr::mutate(lon=purrr::map_dbl(geometry, ~sf::st_centroid(.x)[[1]]), lat=purrr::map_dbl(geometry, ~sf::st_centroid(.x)[[2]])) #reading the shape file


#reading the shape file


locs <- read.csv(here("C:/Users/User/OneDrive - Nexus365/Documents/Idems data/daily_metadata.csv"))
width <- 0.05

last_map <- ggplot2::ggplot() +
  ggplot2::geom_sf(data = hti_admbnda_adm0_cnigs_20181129,  mapping=ggplot2::aes()) + 
  theme_grey() +
  geom_point(data = locs, aes(x = longitude, y = latitude), colour = "black") +
  
 geom_text_repel(data = locs, aes(x = var1, y = var2, label = station, fontface = "italic"), colour = "black", size = 3) 
 
last_map
 
```

```{r gof_fun}
dgof <- function(df, sim, obs, na.rm = TRUE) {
  g <- hydroGOF::gof(sim = df[[sim]], obs = df[[obs]], na.rm = na.rm) # how this function is working? 
  x <- as.list(g)
  names(x) <- row.names(g)
  x
}

comp_stats <- c("r", "ME", "PBIAS %", "MAE", "NSE", "rSD")
names(comp_stats) <- c("Correlation coefficient (1 = Perfect)",
                       "Mean bias (same units)",
                       "Percentage bias (%)",
                       "Mean absolute bias (same units)",
                       "Nash-Sutcliffe efficiency (1 = Perfect)",
                       "Ratio of standard deviations (< 1 less variable, > 1 more variable)")

comp_stats_digits <- c(2, 0, 0, 0, 2, 3)


```

## Yearly Comparisons (August to July)

```{r yearly_calcs}
# view (zm_long) ##this output has been fixed
by_syear <- zm_long %>%
  group_by(syear,station,product) %>%
  summarise(total_rain = sum(naif_nmin(rain, 355)),
            n_rain = sum(naif_nmin(rain, 355) > 0.1),
            max_rain = max(naif_nmin(rain, 350)),
            mean_rain = total_rain/n_rain,
            n_na = sum(is.na(rain))
            
)
# view (by_syear) #seem to have the columns , nrain , max rain etc that we need later on

by_syear_st <- by_syear %>%  #changed from zm_long to by_syear 
  pivot_wider(id_cols = c(station, syear),
              names_from = product, values_from = total_rain:n_na, names_sep = "__") 


# view (by_syear_st)


gof_syear <- by_syear_st %>%  
  group_by(station) %>%
  nest() %>%
  mutate(n = purrr::map_int(data, 
                       ~sum(!is.na(.$total_rain__station) & !is.na(.$total_rain__chirps_rain))), #calculates number of complete years we have 
         gof__total_rain = purrr::map(data, dgof, "total_rain__chirps_rain", "total_rain__station", 
                                      na.rm = TRUE),
         gof__n_rain = purrr::map(data, dgof, "n_rain__chirps_rain", "n_rain__station", na.rm = TRUE),
         gof__mean_rain = purrr::map(data, dgof, "mean_rain__chirps_rain", "mean_rain__station", 
                                     na.rm = TRUE) 
        
  )

view (gof_syear)

gof_pr <- gof_syear %>% 
  unnest(cols = data)

view (gof_pr)
```

```{r yearly_plots_fun}
yearly_plots <- function(df, gof_col, stat_pr, stat_st) {
  max_y <- max(c(df[[stat_pr]], df[[stat_st]]), na.rm = TRUE)
  dat <- df %>% 
    pivot_longer(cols = c(stat_pr, stat_st), names_to = "product", values_to = stat_pr) %>%
    mutate(ME = purrr::map_dbl(.data[[gof_col]], "ME"),
           r = purrr::map_dbl(.data[[gof_col]], "r"),
           rSD = purrr::map_dbl(.data[[gof_col]], "rSD")
           )
  mean_df <- dat %>% 
    group_by(station, product) %>% 
    summarise(m = mean(.data[[stat_pr]], na.rm = TRUE))
  g <- ggplot(dat, aes(x = syear, y = .data[[stat_pr]], colour = product)) +
    geom_line() +
    geom_point() +
    geom_hline(data = mean_df, aes(yintercept = m, colour = product)) +
    scale_x_continuous(limits = c(1979, 2012)) +
    # n
    geom_text(data = dat, aes(label = paste("n", n)), size = 4,
              x = 1979, y = max_y, na.rm = TRUE, 
              inherit.aes = FALSE) +
    # bias
    geom_text(data = dat, aes(label = paste("bias", signif(ME, 2))), 
              size = 4, x = 1979 + 6, y = max_y, na.rm = TRUE, 
              inherit.aes = FALSE) +
    # cor
    geom_text(aes(label = paste("cor", round(r, 2))), 
              size = 4, x = 1979 + 14, y = max_y, na.rm = TRUE, 
              inherit.aes = FALSE) +
    # rSD
    geom_text(aes(label = paste("rSD", round(rSD, 2))), 
              size = 4, x = 1979 + 22, y = max_y, na.rm = TRUE, 
              inherit.aes = FALSE) +
    ggtitle(paste(stat_pr, ":", "CHIRPS", "vs", "station")) +
    facet_wrap(~station)
  g
}
```

```{r stats_tables_fun}
stats_tables <- function(df, obj_col, obj_stats = comp_stats, name) {
  dat <- df %>% 
    ungroup()
  for (i in seq_along(obj_stats)) {
    dat <- dat %>%
      mutate(purrr::map_dbl(df[[obj_col]], obj_stats[i]))
    names(dat)[ncol(dat)] <- obj_stats[i]
  }
  dat <- dat %>% 
    mutate(station = as.character(station))
  dat <- dat[ , c("station", obj_stats)]
  dat %>%
  kable(digits = comp_stats_digits[i], caption = paste("Comparison statistics:", name), 
        format.args = list(big.mark = ",")) %>%
  skable() %>%
  print()
}
```

### Comparison Statistics for Total Yearly Rainfall

- In general all products follow a similar shape each year (high correlation)
- All products, apart from ERA5, estimate the mean quite well (low bias and low percentage bias).
- ERA5 overestimates (high bias) but could be expected as it represents the largest area.
- RFE2 and IMERG look promising across all measures, but few years compared, need the extended station records for better comparison
- Aside from RFE2 and IMERG, CHIRPS performs well over all measures
- Slightly less variability in all products, between 70% - 90% (apart from RFE2 which has roughly the same variability)
- Results for Mansa are generally different across products, indicating possible issues with the station records

```{r yearly_total_plots}

yearly_plots(gof_pr, gof_col = "gof__total_rain", 
                        stat_pr = "total_rain__chirps_rain", 
                        stat_st = "total_rain__station")

ggsave(here("syear_total_rain.png"), width = 12, height = 6)

```

```{r yearly_n_obs, results="asis"}
gof_syear %>% 
  dplyr::select(station, n) %>%
  kable(caption = "Number of years compared") %>%
  skable()
```

```{r yearly_total_rain_tables, results="asis"}
stats_tables(gof_syear, "gof__total_rain", name = "Total Yearly Rainfall")
```


### Comparison Statistics for Number of rainy days

- Reasonably good correlation across the products, so similar pattern each year
- All products overestimate number of rainy days with the same threshold
- Wide variation of the bias amount across products, ERA5 has largest bias, CHIPS has lowest
- Almost the same variability for all products
- Results for Mansa are generally different across products, indicating possible issues with the station records

```{r yearly_n_rain_plots}

view (gof_pr)

yearly_plots(gof_pr, gof_col = "gof__n_rain", #provides all the data in bold above the plot 
             
                        stat_pr = "n_rain__chirps_rain", 
                        stat_st = "n_rain__station")

ggsave(here("syear_n_rain.png"), width = 12, height = 6)

#want to change the y axis to read n_rain instead of chirps
```

```{r yearly_n_rain_tables, results="asis"}

view(gof_syear)
stats_tables(gof_syear, "gof__n_rain", name = "number of rain days ")
```

## Monthly Comparisons (November to April)

```{r monthly_calcs}
by_month <- zm_long %>%
  group_by(station, syear, month_abb, product) %>%
  #filter(month %in% c(11:12, 1:4)) %>%
  summarise(total_rain = sum(naif_nmin(rain, 25)),  
            n_rain = sum(naif_nmin(rain, 25) > 0.1),  
            max_rain = max(naif_nmin(rain, 20)), 
            mean_rain = total_rain/n_rain , 
            n_na = sum(is.na(rain))
            )

by_month_st <- by_month %>%
  pivot_wider(id_cols = c(station, syear, month_abb), 
              names_from = product, values_from = total_rain:n_na, names_sep = "__") 
#%>%
 # pivot_longer(cols = -c(station, syear, month_abb, ends_with("station")), 
  #             names_to = c(".value", "product"), names_sep = "__")







by_month_st$mean_rain__station[is.nan(by_month_st$mean_rain__station)]<-0     #our mean rain solution comes out undetermined when the number of rain days and the total rain are 0
by_month_st$mean_rain__chirps_rain[is.nan(by_month_st$mean_rain__chirps_rain)]<-0
by_month_st$mean_rain__station[is.infinite(by_month_st$mean_rain__station)]<-0     #our mean rain solution comes out undetermined when the number of rain days and the total rain are 0
by_month_st$mean_rain__chirps_rain[is.infinite(by_month_st$mean_rain__chirps_rain)]<-0
view (by_month_st)

gof_month <- by_month_st %>%
  group_by(station) %>%
  nest() %>%
  mutate(n = purrr::map_int(data, 
                        ~sum(!is.na(.$total_rain__station) & !is.na(.$total_rain__chirps_rain))),
         gof__total_rain = purrr::map(data, dgof, "total_rain__chirps_rain", "total_rain__station", 
                                      na.rm = TRUE),
         gof__n_rain = purrr::map(data, dgof, "n_rain__chirps_rain", "n_rain__station", na.rm = TRUE),
         gof__mean_rain = purrr::map(data, dgof, "mean_rain__chirps_rain", "mean_rain__station", 
                                      na.rm = TRUE)
         )


view (gof_month)

gof_pr_month <- gof_month %>%
  unnest(cols = data)
  
#%>% 
  #group_by(product) %>% 
  n#est()
```

```{r monthly_plots_fun}
monthly_plots <- function(df, stat_pr, stat_st, product_name) {
  vals_relace <- c(product_name, "station")
  names(vals_relace) <- c(stat_pr, stat_st)
  dat <- df %>% 
    filter(month_abb %in% month.abb[c(1:12)]) %>%
    pivot_longer(cols = c(stat_pr, stat_st), names_to = "product", values_to = stat_pr) %>%
    mutate(product = recode(product, !!!vals_relace))

  mean_df <- dat %>% 
    group_by(station, product, month_abb) %>% 
    summarise(m = mean(.data[[stat_pr]], na.rm = TRUE))

  g <- ggplot(dat, aes(x = syear, y = .data[[stat_pr]], colour = product)) +
    geom_line() +
    geom_point() +
    geom_hline(data = mean_df, aes(yintercept = m, colour = product)) +
    scale_x_continuous(limits = c(1979, 2012)) +
    ggtitle(paste(stat_pr, ":", product_name, "vs", "station")) +
    facet_grid(station~month_abb)
  g
}
```

### Comparison statistics for total monthly rainfall
- In general all products follow a similar shape each year (high correlation)
- All products, apart from ERA5, estimate the mean quite well (low bias and low percentage bias), with a very slight underestimation compared to yearly totals
- ERA5 overestimates (high bias) but could be expected as it represents the largest area.
- Aside from RFE2 and IMERG, CHIRPS performs well over all measures
- Slightly less variability in all products, between 80% - 100%
- Generally higher correlations and better s.d. ratios than yearly totals
- Results for Mansa are generally different across products, indicating possible issues with the station records

```{r monthly_plots_total_rain}

view (gof_pr_month)

monthly_plots(gof_pr_month, #provides all the data in bold above the plot 
             
                        stat_pr = "total_rain__chirps_rain", 
                        stat_st = "total_rain__station", product_name = "a") #product_name = a is a dummy variable at the momment

ggsave(here("smonth_total_rain.png"), width = 12, height = 6)



#p_month_total <- gof_pr_month %>%
 # mutate(p = purrr::map(data, monthly_plots, stat_pr = "total_rain", 
  #                      stat_st = "total_rain__station", product_name = product),
   #      paths = here("results", "zambia", 
    #                  paste0("zambia_", "month_", "total_rain", "_", product, ".png")))

#walk2(p_month_total$paths, p_month_total$p, ggsave, width = 12, height = 6)
#walk(p_month_total$p, print)
```

```{r monthly_tables_total_rain, results="asis"}

view (gof_month)
stats_tables(gof_month, "gof__total_rain", name = "total_rain_stats")
```

### Comparison statistics for number of monthly raindays
- Generally high correlation for all products
- As shown in the Markov Chain models, the bias varies across products, between 1 - 14 days per month. ARC2 & CHIRPS lowest (1-2 days), TAMSAT (3 days), IMERG & RFE2 (6-7 days), ERA5 (14 days)
- Generally the products have the same or slightly higher variability

```{r monthly_plots_n_rain}
view(gof_pr_month)

monthly_plots(gof_pr_month, 
             
                        stat_pr = "n_rain__chirps_rain", 
                        stat_st = "n_rain__station", product_name = "a") #product_name = a is a dummy variable at the momment

ggsave(here("smonth_n_rain.png"), width = 12, height = 6)

#p_month_total <- gof_pr_month %>%
 # mutate(p = purrr::map(data, monthly_plots, stat_pr = "n_rain", 
  #                      stat_st = "n_rain__station", product_name = product),
   #      paths = here("results", "zambia", 
    #                  paste0("zambia_", "month_", "n_rain", "_", product, ".png")))

#walk2(p_month_total$paths, p_month_total$p, ggsave, width = 12, height = 6)
#walk(p_month_total$p, print)
```

```{r monthly_tables_n_rain, results="asis"}
stats_tables(gof_month, "gof__n_rain", name = "n_rain_stats_month" )

```

## Markov Chain models of the chance of rain

- All products model the same shape of chance of rain
- All overestimate the chance of rain
- With a higher rain day threshold on the product data the probabilities can be made to match very closely
- Threshold between 2 and 5 mm depending on the product
     - ARC2: 4mm
     - CHIRPS: 4-5mm
     - ERA5: > 5mm
     - IMERG: 2-4mm
     - RFE2: 4mm
     - TAMSAT: 5mm
- The optimum threshold may depend on the station

```{r markov_chain_setup}
zambia_markov <- zm_long_st %>% 
  filter(!is.na(rain) & !is.na(pr_rain)) %>%
  mutate(rainday1 = rain > 0.85,
         pr_rainday1 = pr_rain > 0.85,
         pr_rainday3 = pr_rain > 3,
         pr_rainday4 = pr_rain > 4,
         pr_rainday5 = pr_rain > 5,
         pr_rainday2max = pr_rain > 1 & pr_rain <= 2,
         pr_rainday3max = pr_rain > 1 & pr_rain <= 3,
         pr_rainday4max = pr_rain > 1 & pr_rain <= 4,
         pr_rainday5max = pr_rain > 1 & pr_rain <= 5)

f_zero_order_station <- rainday1 ~ (cos(s_doy * 1 * 2 * pi/366) +
                                    sin(s_doy * 1 * 2 * pi/366) + 
                                    cos(s_doy * 2 * 2 * pi/366) + 
                                    sin(s_doy * 2 * 2 * pi/366) +
                                    cos(s_doy * 3 * 2 * pi/366) +
                                    sin(s_doy * 3 * 2 * pi/366))
f_zero_order_product <- update.formula(f_zero_order_station, pr_rainday1 ~ .)

predict_stack_lst <- list()
for(s in seq_along(stations)) {
  predict_df <- data.frame(station = stations[s], s_doy = 1:366,
                           s_doy_date = as.Date(1:366, origin = as.Date("1999/07/31")))
  dat <- zambia_markov %>%
    filter(station == stations[s])
  for(i in seq_along(products)) {
    dat_prod <- dat %>%
      filter(product %in% c("station", products[i])) %>% 
      filter(!is.na(rain) & !is.na(pr_rain))
    zero_order_station <- glm(f_zero_order_station, data = dat_prod, family = binomial)
    zero_order_product <- glm(f_zero_order_product, data = dat_prod, family = binomial)
    #print(anova(zero_order_station, test="Chisq"))
    predict_df[[paste0("station", "_", products[i])]] <- predict(zero_order_station, 
                                                                 newdata = predict_df, 
                                                                 type = "response")
    predict_df[[products[i]]] <- predict(zero_order_product, newdata = predict_df, 
                                         type = "response")
    
    f_zero_order_product_3thres <- update.formula(f_zero_order_station, pr_rainday3 ~ .)
    f_zero_order_product_4thres <- update.formula(f_zero_order_station, pr_rainday4 ~ .)
    f_zero_order_product_5thres <- update.formula(f_zero_order_station, pr_rainday5 ~ .)
    f_zero_order_product_2max <- update.formula(f_zero_order_station, pr_rainday2max ~ .)
    f_zero_order_product_3max <- update.formula(f_zero_order_station, pr_rainday3max ~ .)
    f_zero_order_product_4max <- update.formula(f_zero_order_station, pr_rainday4max ~ .)
    f_zero_order_product_5max <- update.formula(f_zero_order_station, pr_rainday5max ~ .)
    fms <- list(f_zero_order_product_2max, f_zero_order_product_3max, 
                f_zero_order_product_4max, f_zero_order_product_5max)
    fms_thres <- list(f_zero_order_product_3thres, f_zero_order_product_4thres,
                      f_zero_order_product_5thres)
    mds <- list()
    for(j in 2:(2 + length(fms) - 1)) {
      zero_order <- glm(fms[[j - 1]], data = dat_prod, family = binomial)
      predict_df[[paste0(products[i], "_", j, "max")]] <- predict(zero_order, 
                                                                  newdata = predict_df, 
                                                                  type = "response")
    }
    for(j in 3:(3 + length(fms_thres) - 1)) {
      zero_order <- glm(fms_thres[[j - 2]], data = dat_prod, family = binomial)
      predict_df[[paste0(products[i], "_", j, "thres")]] <- predict(zero_order, 
                                                                    newdata = predict_df, 
                                                                    type = "response")
    }
  }
  
  predict_stack <- predict_df %>% melt(id.vars = c("station", "s_doy", "s_doy_date"), 
                                       variable.name = "product", value.name = "prob")

  predict_stack$product <- as.character(predict_stack$product)
  predict_stack$product2 <- predict_stack$product
  predict_stack$type <- "product1"
  
  predict_stack <- predict_stack %>% 
    mutate(type = ifelse(startsWith(product, "station"), "station1", type),
           type = ifelse(endsWith(product, "max"), 
                         substr(product, nchar(product) - 3, nchar(product)), type),
           type = ifelse(endsWith(product, "thres"), 
                         substr(product, nchar(product) - 5, nchar(product)), type),
           product2 = ifelse(startsWith(product, "station"), 
                             substr(product, 9, nchar(product)), product2),
           product2 = ifelse(endsWith(product, "max"), 
                             substr(product, 1, nchar(product) - 5), product2),
           product2 = ifelse(endsWith(product, "thres"), 
                             substr(product, 1, nchar(product) - 7), product2)
           )
  
  predict_stack$type <- factor(predict_stack$type, levels = unique(predict_stack$type))
  predict_stack_lst[[length(predict_stack_lst) + 1]] <- predict_stack
  # Plot small amounts
  # g <- ggplot(predict_stack, aes(x = s_doy, y = prob, colour = type)) +
  #   geom_line() +
  #   facet_wrap(~product2) +
  #   scale_color_manual(values = c("black", c25[1:7])) +
  #   ggtitle(paste("Chance of rain:", stations[s]))
  # ggsave(here("results", "zambia", paste0("zambia_", "markov_zero", stations[s], ".png")), 
  #        plot = g, width = 12, height = 6)
}
predict_stack_all <- bind_rows(predict_stack_lst)
```

```{r markov_chain_plots_stations}
for(s in seq_along(stations)) {
  dat <- predict_stack_all %>% filter(station == stations[s] & !grepl("max", type))
  g <- ggplot(dat, aes(x = s_doy_date, y = prob, colour = type, size = type)) +
    geom_line() +
    facet_wrap(~product2) +
    scale_size_manual(values = c(0.8, rep(0.6, 4))) +
    scale_color_manual(values = c("black", c25[1:4])) +
    scale_x_date(date_breaks = "2 months", date_labels = "%b") +
    ggtitle(paste("Chance of rain:", stations[s]))
  print(g)
  ggsave(here("results", "zambia", 
              paste0("zambia_", "markov_zero", "_station_", stations[s], ".png")),
         plot = g, width = 12, height = 6)
}
```

```{r markov_chain_plots_products}
for(s in seq_along(products)) {
  dat <- predict_stack_all %>% 
    filter(product2 == products[s] & !grepl("max", type))
  g <- ggplot(dat, aes(x = s_doy_date, y = prob, 
                       colour = type, size = type, linetype = type)) +
    geom_line() +
    facet_wrap(~station) +
    scale_color_manual(values = c("black", viridis(4, end = 0.8))) +
    scale_size_manual(values = c(1.3, rep(0.8, 4))) +
    scale_x_date(date_breaks = "2 months", date_labels = "%b") +
    scale_linetype_manual(values = c("solid", rep("longdash", 4))) +
    ggtitle(paste("Chance of rain:", products[s]))
  print(g)
  ggsave(here("results", "zambia", 
              paste0("zambia_", "markov_zero", "_product_", names(products)[s], ".png")),
         plot = g, width = 12, height = 6)
}
```

### Distribution of rainfall amounts

```{r}
for(i in c(50, 10, 5)) {
g <- ggplot(zm_long %>% filter(rain > 0.85), aes(x = rain, colour = product)) +
  stat_ecdf(aes(size = product), pad = FALSE, geom = "step") +
  coord_cartesian(xlim = c(NA, i)) +
  scale_color_manual(values = c("black", c25[1:length(products)])) +
  scale_size_manual(values = c(1, rep(0.5, length(products)))) +
  facet_wrap(~station)
print(g)
}
```

```{r}
for(i in c(200, 50, 10, 5, 2, 1)) {
  g <- ggplot(zm_long %>% filter(rain > 0), 
              aes(x = rain, y = after_stat(density), colour = product)) +
    geom_freqpoly(aes(size = product), binwidth = 0.5, centre = 0.5) +
    scale_color_manual(values = c("black", c25[1:length(products)])) +
    scale_size_manual(values = c(1, rep(0.5, length(products)))) +
    scale_x_continuous(limits = c(0, NA)) +
    coord_cartesian(xlim = c(NA, i)) +
    facet_wrap(~station)
  print(g)
}
```

```{r}
prop_amounts <- zm_long %>%
  filter(rain > 0.85 & station == "Livingstone") %>%
  mutate(rain_grps = cut(rain,
                          breaks = c(0, 0.85, 1.1, 2.1, 3.1, 4.1, 5.1, 10, 20, 30, 50, 200),
                          include.lowest = TRUE)) %>%
  group_by(product, rain_grps) %>%
  summarise(n = n()) %>%
  mutate(prop = n/sum(n), cumul = cumsum(prop))

ggplot(prop_amounts, aes(x = rain_grps, y = prop, fill = product)) +
  geom_col(position = "dodge")

prop_amounts %>%
  pivot_wider(names_from = product, values_from = cumul, id_cols = rain_grps) %>%
  kable(digits = 2) %>%
  skable()
```

### Detection of rainfall on the same days (November to April)

![](cont_table.jpg)

- In general these results confirm what was seen above
- 75% accuracy for all products apart from ERA5 (66%)
- High bias for all products, as already known (more rainy days estimated than observed)
- High hit rate and false alarm ratios, which is expected because of high bias
- All apart from ERA5 perform well on threat score, which only considers how well it estimates rainy days
- Proportion of misses is reassuringly low across products
- Performance will change if different thresholds are introduced

```{r raindays_verify}
raindays <- zm_long_st %>% 
  mutate(st_rainday0p85 = rain > 0.85,
         pr_rainday0p85 = pr_rain > 0.85,
         pr_rainday3 = pr_rain > 3,
         pr_rainday5 = pr_rain > 5)

sverify <- function(df, obs, pred) {
  v <- verification::verify(obs = df[[obs]], pred = df[[pred]], 
                       obs.type = "binary", frcst.type = "binary")
  class(v) <- "list"
  v
}

by_st_pr <- raindays %>%
  group_by(station, product) %>%
  nest() %>%
  mutate(v = purrr::map(data, sverify, obs = "st_rainday0p85", pred = "pr_rainday0p85"),
         bias = purrr::map_dbl(v, "BIAS"))
```

```{r cont_tables, results="asis"}
cont_tables <- function(df, name) {
  df %>%
    kable(caption = name, digits = 2, format.args = list(big.mark = ",")) %>%
    skable() %>%
    row_spec(nrow(df), bold = TRUE)
}

rain_levs <- c("rain", "no_rain")
ver_zm <- raindays %>%
  group_by(product, station) %>%
  filter(month %in% c(11:12, 1:4)) %>%
  filter(!is.na(st_rainday0p85) & !is.na(pr_rainday0p85)) %>%
  summarise(hit = sum(st_rainday0p85 & pr_rainday0p85),
            fa = sum(!st_rainday0p85 & pr_rainday0p85),
            miss = sum(st_rainday0p85 & !pr_rainday0p85),
            cneg = sum(!st_rainday0p85 & !pr_rainday0p85),
            n = n(),
            accuracy = (hit + cneg)/n,
            bias = (hit + fa)/(hit + miss),
            hit_rate = hit/(hit + miss),
            far = fa/(hit + fa),
            ts = hit/(hit + miss + fa),
            ets = verification::verify(obs = st_rainday0p85, pred = pr_rainday0p85, 
                                       obs.type = "binary", frcst.type = "binary")$ETS,
            miss_frac = miss/n,
            hk = (hit/(hit + miss) - (fa/(fa + cneg))),
            hss = verification::verify(obs = st_rainday0p85, pred = pr_rainday0p85, 
                                       obs.type = "binary", frcst.type = "binary")$HSS
            ) %>%
  arrange(product, station)

measures <- c("accuracy", "bias", "hit_rate", "far", "ts", "ets", "miss_frac", "hk", "hss")
names(measures) <- c("Accuracy: What fraction of the estimates were correct?
                     (hits + correct negative)/total (1 = perfect)",
                     "Bias: Ratio of number of rain days from estimate over number of rain days from station. 
                     (hits + false alarms)/(hits + misses) (1 = perfect)",
                     "Hit rate (probability of detection) What fraction of the station rain days were correctly estimated? hits/(hits + misses) (1 = perfect)",
                     "False alarm ratio: What fraction of the estimated rain days actually did not rain? false alarms/(hits + false alarms)",
                     "Threat score: How well did the estimate rain days correspond to the observed rain days?",
                     "Equitable threat score: How well did the estimate rain days correspond to the station rain days (accounting for hits due to chance)?",
                     "Proportion of misses: How many rain days in the station were not detected by the estimate?",
                     "Hanssen and Kuipers discriminant: How well did the forecast separate the rainy days from the dry days? Uses all elements in the contingency table.",
                     "Heidke skill score: What was the accuracy of the forecast relative to that of random chance? Measures the fraction of correct estimates after eliminating those estimates which would be correct due purely to random chance."
                     )
for(i in seq(measures)) {
  df <- ver_zm %>% 
    select(product, station, measures[[i]]) %>%
    pivot_wider(id_cols = station, names_from = product, values_from = measures[[i]])
  names(df)[endsWith(names(df), "rain")] <- substr(names(df)[endsWith(names(df), "rain")],
                                                   1, 
                                                   nchar(names(df)
                                                         [endsWith(names(df), "rain")]
                                                         ) 
                                                   - 5)
  df[nrow(df) + 1, ] <- c(list("(All)"), as.list(as.numeric(colMeans(df[ , -1]))))
  print(cont_tables(df, names(measures)[i]))
}
```

